# 01 大模型与 LLM 概览

> 本文档由 Vibe Writing 大模型生成初稿，并结合本仓库实践与个人学习需求进行整理与校订。

这是一篇从「为什么大模型这么火」开始，逐步落到「语言模型到底在干什么」的入门文章。更准确一点，它是我在折腾 MiniMind 这套代码时，给自己写的总览笔记：先把大图景搞清楚，再去对应到具体的 `model/`、`trainer/` 与 `scripts/` 目录。

## 1. 本篇目标

- 搞清楚「语言模型」和「大语言模型（LLM）」分别指什么。
- 用直观类比理解：为什么只靠「预测下一个 token」就能涌现出各种“智能”行为。
- 从时间线的角度看看：从传统 NLP 到如今的预训练大模型，中间发生了哪些关键变化。
- 用一条流程线，串起 MiniMind 代码里各个脚本的大致位置。

## 2. 什么是语言模型？

如果把自然语言看成一串 token（可以是字、词或子词），那么**语言模型（Language Model）**要解决的问题非常朴素：

> 给定前面的一串 token，预测下一个最可能出现的 token 是什么。

形式上，经常会写成：

> P(next_token | previous_tokens)

在工程上，我们不会真的一次只预测一个 token，而是：

1. 把一整段文本切成 token 序列（比如长度为 512）。
2. 让模型在每个位置都预测“下一个 token”。
3. 用交叉熵等损失函数，把所有预测误差加总起来训练。

从这个角度看，语言模型更像一个超强的「自动补全」模块：

- 你打出一句话的前半句，它帮你猜后半句；
- 你写出一段代码的开头，它帮你续写剩余部分。

几乎所有的 LLM，本质上都是在做这件事，只是模型变得足够大、数据足够多，外加各种训练技巧，才有了今天这种“会聊天、会写代码、会推理”的效果。

## 3. 什么是“大语言模型（LLM）”

既然语言模型的定义如此简单，那「大」体现在哪里？

可以粗暴地看三件事：

- **参数量**：从早期几百万 / 几千万参数，到现在几十亿、上百亿甚至上千亿参数。
- **数据量**：从单一任务的小数据集，到覆盖多语言、多领域的海量文本。
- **能力边界**：从只会做「一件事」（比如情感分类），到可以**一模型多任务**，甚至能够“零样本”处理没见过的任务。

典型代表：

- GPT 系列（OpenAI）
- LLaMA / Llama 3 系列（Meta）
- Qwen 系列（阿里）
- DeepSeek 系列

这些模型往往有一整条家族谱系：不同参数规模（7B/13B/70B…），不同用途（base / instruct / chat / vlm），但底层都是一类 Transformer 解码器结构。

在 MiniMind 里，我们做的是一个「极小版本」的大语言模型：

- 参数量只有几十 M，远远小于主流大模型，但是结构上高度类似；
- 好处是：便宜、可控，可以在个人显卡上完整走一遍训练—微调—推理的流程。

## 4. 从传统 NLP 到预训练 LLM：一次范式切换

回顾一下 NLP 的发展脉络，大致可以分成几代：

### 4.1 统计语言模型：n-gram 时代

- 假设当前词只和前面 n−1 个词有关，比如：
  - 三元组（trigram）：P(w_t | w_{t-1}, w_{t-2})
- 通过统计大规模语料中 n-gram 的共现频率，估计概率。
- 问题：
  - 维度灾难：n 一大，组合数爆炸。
  - 稀疏：很多组合从未在训练语料中出现。
  - 只能建“词表级”的统计关系，无法表达更复杂的语义。

### 4.2 神经网络语言模型与词向量

后来引入了神经网络：

- 通过嵌入层（embedding）把词映射到稠密向量（word2vec、GloVe）。
- 使用前馈网络或 RNN 建模序列关系。

这一代的典型成果：

- 词向量可以捕捉一些有趣的语义关系（king - man + woman ≈ queen）。
- 但模型通常还是针对**某个具体任务**训练，迁移能力有限。

### 4.3 预训练 + 微调：一个模型统领多任务

真正的范式切换发生在**预训练（Pretrain） + 微调（Fine-tune）**出现之后：

1. 先在海量无标注文本上，做「自监督学习」（预测被 mask 掉的词 / 下一个词）。
2. 再在具体任务上用少量标注数据做微调。

好处是：

- 预训练阶段让模型学到通用语言知识；
- 微调阶段只需要为特定任务“加一点偏好”。

MiniMind 中，你可以在 `trainer/train_pretrain.py` 里看到预训练脚本的实现，而 `trainer/train_full_sft.py`、`trainer/train_lora.py` 则对应后续的指令微调阶段。

## 5. LLM 的典型应用场景

当模型规模足够大、数据足够广、训练足够稳之后，一个通用 LLM 在应用上大致可以做几类事情：

### 5.1 对话助手与代码助手

- ChatGPT、Claude 这类聊天机器人；
- GitHub Copilot、Cursor 这类代码补全与重构助手。

本质上都是「给一个上下文，让模型继续生成后续 token」，只是界面与增强机制不同。

### 5.2 各种文本生成任务

- 写摘要、改写、风格迁移；
- 文案生成、故事续写；
- 把非结构化文本整理成结构化信息。

### 5.3 信息检索与问答（RAG）

- 检索增强生成（RAG）：先从知识库中取出相关文档，再让 LLM 根据这些文档回答问题；
- 这样可以弥补模型参数中「记忆」的局限，同时便于更新知识。

在工程上，这类系统通常会：

- 使用向量数据库（如 faiss、milvus、pgvector 等）做相似度检索；
- 在调用 LLM 之前，把检索结果拼接到 prompt 中。

### 5.4 Agent 与工具调用

- 让模型根据目标自主规划调用「工具」（例如搜索、计算器、数据库查询等）；
- 模型不再只是输出一段文本，而是通过外部工具改变世界状态。

MiniMind 的体量更适合作为「算法教学与实践」载体，但思路上和这些应用是一致的。

## 6. 一个 LLM 的完整生命周期

从工程视角看，一个 LLM 的生命周期可以简单画成四个阶段：

1. **数据准备**
   - 收集、清洗、去重、切分预训练语料；
   - 构造指令微调数据、偏好数据等。
2. **预训练**
   - 在大规模语料上做自监督训练；
   - 这一阶段通常最耗算力。
3. **对齐与微调**
   - 指令微调（SFT）：让模型更「听指令」；
   - RLHF / DPO / RLAIF 等：让模型更「符合人类偏好」。
4. **部署与监控**
   - 推理服务、延迟与吞吐量优化；
   - 在线监控与安全控制。

在本仓库中，大致可以这样对应：

- `dataset/`：与数据准备相关的代码。
- `model/`：模型结构与分词器定义。
- `trainer/`：预训练、SFT、LoRA、DPO、PPO/GRPO/SPO 等训练脚本。
- `scripts/`：推理与服务相关脚本（如 `serve_openai_api.py`、`chat_openai_api.py`）。

你可以把这一篇当成「地图」：先在脑中形成一个 LLM 的整体形状，然后再去读其它几篇基础知识（Tokenizer、Transformer、预训练、对齐、部署），以及对应的源码与脚本。

## 7. 延伸阅读与思考

- 推荐阅读：
  - 主流开源模型（Llama 3、Qwen、DeepSeek 等）的技术报告与 README。
  - 本仓库上游项目 MiniMind 的原始说明文档，用来对比两边的设计取舍。
- 思考题：
  - 仅仅通过「预测下一个 token」这一个目标，为什么会涌现出对话、推理、写代码等复杂能力？
  - 如果把模型规模缩小很多（比如像 MiniMind 一样几十 M），哪些能力会最先消失？哪些能保留？
